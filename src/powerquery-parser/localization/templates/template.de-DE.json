{
  "error_common_cancellationError": "CancellationError: Es wurde eine Abbruchanforderung erstellt.",
  "error_common_invariantError_1_details": "InvariantError: {invariantBroken} – {details}",
  "error_common_invariantError_2_noDetails": "InvariantError: {invariantBroken}",
  "error_common_unknown": "Unbekannter Fehler, innerError: {innerError}",
  "error_lex_badLineNumber_1_greaterThanNumLines": "lineNumber ist größer als oder gleich der Anzahl von Zeilen.",
  "error_lex_badLineNumber_2_lessThanZero": "lineNumber ist kleiner als oder gleich 0.",
  "error_lex_badRange_1_lineNumberEnd_greaterThanLineLength": "end.lineCodeUnit ist höher als die Länge der Zeile.",
  "error_lex_badRange_2_lineNumberEnd_greaterThanLineNumbers": "end.lineNumber ist höher als die Anzahl von State-Zeilen.",
  "error_lex_badRange_3_lineNumberStart_greaterThanLineLength": "start.lineCodeUnit ist höher als die Länge der Zeile.",
  "error_lex_badRange_4_lineNumberStart_greaterThanLineNumberEnd": "start.lineNumber ist größer als end.lineNumber.",
  "error_lex_badRange_5_lineNumberStart_greaterThanNumLines": "start.lineNumber ist höher als die Anzahl von State-Zeilen.",
  "error_lex_badRange_6_lineNumberStart_lessThanZero": "start.lineNumber ist kleiner als 0.",
  "error_lex_badRange_7_sameLine_codeUnitStartGreaterThanCodeUnitEnd": "Anfang und Ende haben dieselbe Zeile gemeinsam verwendet, aber start.lineCodeUnit war höher als end.lineCodeUnit.",
  "error_lex_badState": "Der Lexer hat einen Fehler bei der letzten Ausführung festgestellt. Geben Sie mehr Text für den Lexer an, oder überprüfen Sie den vorherigen Fehler.",
  "error_lex_endOfStream": "Der Lexer hat das Streamende erreicht.",
  "error_lex_endOfStreamPartwayRead": "Beim Lesen eines Tokens wurde der Dokumentdatenstrom vorzeitig beendet.",
  "error_lex_expectedKind_1_hex": "Es wurde ein hexidezimales Literal erwartet.",
  "error_lex_expectedKind_2_keywordOrIdentifier": "Es wurde ein Schlüsselwort oder ein Bezeichner erwartet.",
  "error_lex_expectedKind_3_numeric": "Es wurde ein numerisches Literal erwartet.",
  "error_lex_lineMap": "Fehler in Zeile(n): {lineNumbers}",
  "error_lex_unexpectedRead": "Unerwarteter Lesevorgang während der Tokenisierung.",
  "error_lex_unterminatedMultilineToken_1_comment": "Nicht abgeschlossener mehrzeiliger Kommentar.",
  "error_lex_unterminatedMultilineToken_2_quotedIdentifier": "Nicht abgeschlossener Bezeichner in Anführungszeichen.",
  "error_lex_unterminatedMultilineToken_3_string": "Nicht abgeschlossene Zeichenfolge.",
  "error_parse_csvContinuation_1_danglingComma": "Haben Sie ein abschließendes Komma übersehen?",
  "error_parse_csvContinuation_2_letExpression": "Ein Komma darf nicht vor \"in\" stehen",
  "error_parse_expectAnyTokenKind_1_other": "{foundTokenKind} gefunden, aber eines der folgenden Token erwartet: {expectedAnyTokenKinds}",
  "error_parse_expectAnyTokenKind_2_endOfStream": "Streamende erreicht, aber eines der folgenden Token erwartet: {expectedAnyTokenKinds}",
  "error_parse_expectGeneralizedIdentifier_1_other": "Es wurde ein generalisierter Bezeichner erwartet.",
  "error_parse_expectGeneralizedIdentifier_2_endOfStream": "Es wurde ein generalisierter Bezeichner erwartet, aber vorher wurde das Streamende erreicht.",
  "error_parse_expectTokenKind_1_other": "Erwartet: {expectedTokenKind}, gefunden: {foundTokenKind}.",
  "error_parse_expectTokenKind_2_endOfStream": "Es wurde ein Token vom Typ \"{expectedTokenKind}\" erwartet, aber stattdessen wurde das Streamende erreicht.",
  "error_parse_invalidCatchFunction": "The 'catch' clause of a try/catch expression must be followed by a function definition with 0 or 1 arguments and no type constraints",
  "error_parse_invalidPrimitiveType": "Es wurde ein primitives Literal erwartet, stattdessen jedoch ein Token vom Typ \"{foundTokenKind}\" gefunden.",
  "error_parse_requiredParameterAfterOptional": "Nach einem optionalen Parameter darf kein nicht optionaler Parameter vorhanden sein.",
  "error_parse_unterminated_sequence_bracket": "Nicht abgeschlossene eckige Klammer.",
  "error_parse_unterminated_sequence_parenthesis": "Nicht abgeschlossene Klammer.",
  "error_parse_unusedTokens": "Die Analyse ist abgeschlossen, aber es sind noch weitere Token vorhanden.",
  "tokenKind_ampersand": "kaufmännisches Und-Zeichen <'&'>",
  "tokenKind_asterisk": "Sternchen <'*'>",
  "tokenKind_atSign": "@-Zeichen <'@'>",
  "tokenKind_bang": "Ausrufezeichen <'!'>",
  "tokenKind_comma": "Komma <','>",
  "tokenKind_division": "Divisionsoperator <'/'>",
  "tokenKind_dotDot": "Punkt Punkt <'..'>",
  "tokenKind_ellipsis": "Auslassungszeichen <'...'>",
  "tokenKind_equal": "Gleichheitsoperator <'='>",
  "tokenKind_fatArrow": "wechselt zu ('=>')",
  "tokenKind_greaterThan": "Größer-als-Operator ('>')",
  "tokenKind_greaterThanEqualTo": "Größer-als- oder Gleichheitsoperator ('>=')",
  "tokenKind_hexLiteral": "hexadezimales Literal",
  "tokenKind_identifier": "ID",
  "tokenKind_keywordAnd": "Schlüsselwort <'and'>",
  "tokenKind_keywordAs": "Schlüsselwort <'as'>",
  "tokenKind_keywordEach": "Schlüsselwort <'each'>",
  "tokenKind_keywordElse": "Schlüsselwort <'else'>",
  "tokenKind_keywordError": "Schlüsselwort <'error'>",
  "tokenKind_keywordFalse": "Schlüsselwort <'false'>",
  "tokenKind_keywordHashBinary": "Schlüsselwort <'#binary'>",
  "tokenKind_keywordHashDate": "Schlüsselwort <'#date'>",
  "tokenKind_keywordHashDateTime": "Schlüsselwort <'#datetime'>",
  "tokenKind_keywordHashDateTimeZone": "Schlüsselwort <'#datetimezone'>",
  "tokenKind_keywordHashDuration": "Schlüsselwort <'#duration'>",
  "tokenKind_keywordHashInfinity": "Schlüsselwort <'#infinity'>",
  "tokenKind_keywordHashNan": "Schlüsselwort <'#nan'>",
  "tokenKind_keywordHashSections": "Schlüsselwort <'#sections'>",
  "tokenKind_keywordHashShared": "Schlüsselwort <'#shared'>",
  "tokenKind_keywordHashTable": "Schlüsselwort <'#table'>",
  "tokenKind_keywordHashTime": "Schlüsselwort <'#time'>",
  "tokenKind_keywordIf": "Schlüsselwort <'if'>",
  "tokenKind_keywordIn": "Schlüsselwort <'in'>",
  "tokenKind_keywordIs": "Schlüsselwort <'is'>",
  "tokenKind_keywordLet": "Schlüsselwort <'let'>",
  "tokenKind_keywordMeta": "Schlüsselwort <'meta'>",
  "tokenKind_keywordNot": "Schlüsselwort <'not'>",
  "tokenKind_keywordOr": "Schlüsselwort <'or'>",
  "tokenKind_keywordOtherwise": "Schlüsselwort <'otherwise'>",
  "tokenKind_keywordSection": "Schlüsselwort <'section'>",
  "tokenKind_keywordShared": "Schlüsselwort <'shared'>",
  "tokenKind_keywordThen": "Schlüsselwort <'then'>",
  "tokenKind_keywordTrue": "Schlüsselwort <'true'>",
  "tokenKind_keywordTry": "Schlüsselwort <'try'>",
  "tokenKind_keywordType": "Schlüsselwort <'type'>",
  "tokenKind_leftBrace": "linke geschweifte Klammer <'{'>",
  "tokenKind_leftBracket": "linke eckige Klammer <'['>",
  "tokenKind_leftParenthesis": "linke runde Klammer <'('>",
  "tokenKind_lessThan": "Kleiner-als-Operator ('<')",
  "tokenKind_lessThanEqualTo": "Kleiner-als- oder Gleichheitsoperator ('<=')",
  "tokenKind_minus": "Minus <'-'>",
  "tokenKind_notEqual": "Ungleichheitsoperator ('<>')",
  "tokenKind_nullCoalescingOperator": "NULL-Sammeloperator <'??'>",
  "tokenKind_nullLiteral": "<'null'>",
  "tokenKind_numericLiteral": "numerisches Literal",
  "tokenKind_plus": "Additionsoperator <'+'>",
  "tokenKind_questionMark": "Fragezeichen <'?'>",
  "tokenKind_rightBrace": "rechte geschweifte Klammer <'}'>",
  "tokenKind_rightBracket": "rechte eckige Klammer <']'>",
  "tokenKind_rightParenthesis": "rechte runde Klammer <')'>",
  "tokenKind_semicolon": "Semikolon <';'>",
  "tokenKind_textLiteral": "Text"
}